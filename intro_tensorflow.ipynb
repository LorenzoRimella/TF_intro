{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LorenzoRimella/TF_intro/blob/main/intro_tensorflow.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44TyiGBsbAcr"
   },
   "source": [
    "# TensorFlow: funzionamento e utilizzi pratici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoQIO4kcbAct"
   },
   "source": [
    "Iniziamo con l'importare le librerie principali. La libreria tensorflow è l'oggetto della presentazione, numpy verrà usata per un confronto, time per calcolare i running times, e matplotlib per i grafici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 8617,
     "status": "ok",
     "timestamp": 1695395138778,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "qgUWkKCybAcu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-29 08:59:20.676090: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-29 08:59:21.799298: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-01-29 08:59:21.799338: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-01-29 08:59:21.808567: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-01-29 08:59:22.296566: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-29 08:59:24.652497: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo se abbiamo una GPU disponibile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1053,
     "status": "ok",
     "timestamp": 1695395140361,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "eh0cnK1QbAcw",
    "outputId": "2cb10ee2-f9d7-4cab-ae4d-76cea4b492a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-29 08:59:28.612220: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-29 08:59:31.090240: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-29 08:59:31.090288: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EuQcDz-FbAcx"
   },
   "source": [
    "## Tensori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2ESF-SNbAcx"
   },
   "source": [
    "Creare un tensore da una lista. \n",
    "Notiamo che dobbiamo sempre indicare il tipo di tensore (precisione del computer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3140,
     "status": "ok",
     "timestamp": 1695395179136,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "2Qf9TtqnbAcx",
    "outputId": "97b565cc-f84e-411d-9738-e1014b1cd02c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-29 08:59:31.125476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-29 08:59:31.125569: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-29 08:59:31.125587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-29 08:59:31.276704: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-29 08:59:31.276768: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-29 08:59:31.276774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2026-01-29 08:59:31.276799: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-29 08:59:31.276818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5520 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensore 1 \n",
      " tf.Tensor([100.   1.   1.], shape=(3,), dtype=float32)\n",
      "tensore 2 \n",
      " tf.Tensor(\n",
      "[[100.   1.]\n",
      " [  1.   1.]], shape=(2, 2), dtype=float32)\n",
      "tensore 3 \n",
      " tf.Tensor(\n",
      "[[[100.   1.   2.]\n",
      "  [100.   1.   2.]\n",
      "  [100. 100.   2.]]\n",
      "\n",
      " [[  2.   1.   2.]\n",
      "  [100.   1.   2.]\n",
      "  [  2.   1.   2.]]], shape=(2, 3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_from_list_1 = tf.convert_to_tensor([100, 1, 1], dtype = tf.float32)\n",
    "print(\"tensore 1 \"+\"\\n\", x_from_list_1)\n",
    "\n",
    "x_from_list_2 = tf.convert_to_tensor([[100, 1], [1, 1]], dtype = tf.float32)\n",
    "print(\"tensore 2 \"+\"\\n\", x_from_list_2)\n",
    "\n",
    "x_from_list_3 = tf.convert_to_tensor([[[100, 1, 2], [100, 1, 2], [100, 100, 2]], [[2, 1, 2], [100, 1, 2], [2, 1, 2]]], dtype = tf.float32)\n",
    "print(\"tensore 3 \"+\"\\n\", x_from_list_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fSgFUWkbAcy"
   },
   "source": [
    "Possiamo anche crearlo direttamente da un numpy array. Questo può essere utile per comunicare con altre librerie, es. pandas, nella lettura dei dati. \n",
    "Notiamo che se non specifico il tipo viene assegnato uno di deafult, in questo caso int perché non ci sono virgole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1695395184658,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "zWgKoZ2fbAcy",
    "outputId": "076636f9-ad68-40c3-d3c3-ea43b5087d54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensore da numpy \n",
      " tf.Tensor([100   1   1], shape=(3,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "npx = np.array([100, 1, 1])\n",
    "\n",
    "x_from_numpy = tf.convert_to_tensor(npx)\n",
    "print(\"tensore da numpy \"+\"\\n\", x_from_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mentre in un numpy array possiamo cambiare gli elementi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy array con nuovo elemento \n",
      " [ 100    1 -100]\n"
     ]
    }
   ],
   "source": [
    "npx = np.array([100, 1, 1])\n",
    "\n",
    "npx[2] = -100\n",
    "\n",
    "print(\"numpy array con nuovo elemento \"+\"\\n\", npx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tensori sono immutabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m npx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      3\u001b[0m x_from_numpy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(npx)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mx_from_numpy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "npx = np.array([100, 1, 1])\n",
    "\n",
    "x_from_numpy = tf.convert_to_tensor(npx)\n",
    "\n",
    "x_from_numpy[2] = -100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operazioni tra tensori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operazioni elemento per elemento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrJp-IqYbAcy"
   },
   "source": [
    "Avere lo stesso tipo (compatibili) di tensori ci permette di eseguire operazioni su di essi, ma se non sono compatibili abbiamo un errore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "executionInfo": {
     "elapsed": 998,
     "status": "error",
     "timestamp": 1695395227172,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "IHfWDaNZbAcy",
    "outputId": "f8ee11ed-dbfa-4ddd-bc9d-425263a32e3a"
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute AddV2 as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:AddV2] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_not_compatible_sum \u001b[38;5;241m=\u001b[39m \u001b[43mx_from_numpy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_from_list_1\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfwsl/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tfwsl/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:5888\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5887\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5888\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute AddV2 as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:AddV2] name: "
     ]
    }
   ],
   "source": [
    "x_not_compatible_sum = x_from_numpy + x_from_list_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsGjkdkXbAcz"
   },
   "source": [
    "Se abbiamo tensori compatibili possiamo sommarli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 465,
     "status": "ok",
     "timestamp": 1695395242244,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "fEnSZX1xbAcz",
    "outputId": "5ea317a4-8278-4937-e2cd-ec626db84dff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([200.   2.   2.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_from_numpy_float32 = tf.convert_to_tensor(npx, dtype = tf.float32)\n",
    "x_compatible_sum = x_from_numpy_float32 + x_from_list_1\n",
    "print(x_compatible_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lHr1t-3bAcz"
   },
   "source": [
    "farne la differenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1695395247872,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "SE7n6KK9bAcz",
    "outputId": "ad3ce2ac-4539-4287-cf59-15fe0ef798b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_compatible_diff = x_from_numpy_float32 - x_from_list_1\n",
    "print(x_compatible_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcsDNruUbAcz"
   },
   "source": [
    "moltiplicarli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1695395249739,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "qxirhs3vbAcz",
    "outputId": "c8b72697-0937-4e92-f8dd-92aa2c2ad80d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1.e+04 1.e+00 1.e+00], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_compatible_prod = x_from_numpy_float32 * x_from_list_1\n",
    "print(x_compatible_prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fW8lT0_ubAc0"
   },
   "source": [
    "dividerli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1695395258038,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "gmoO65wPbAc0",
    "outputId": "cf3eacc0-8743-45b7-ddc3-3072a6f61979"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_compatible_div = x_from_numpy_float32 / x_from_list_1\n",
    "print(x_compatible_div)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_DvgoNbbAc0"
   },
   "source": [
    "e praticamente tutto quello che vogliamo: potenze, logaritmi, esponenziali, e altro... Google it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 414,
     "status": "ok",
     "timestamp": 1695395271480,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "WpYuKF4ZbAc0",
    "outputId": "67bd10b0-f659-4a1f-d3cd-905a3cff8b0e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-29 08:59:55.238260: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1.00000006e+06 1.00000000e+00 1.00000000e+00], shape=(3,), dtype=float32)\n",
      "tf.Tensor([4.6051702 0.        0.       ], shape=(3,), dtype=float32)\n",
      "tf.Tensor([      inf 2.7182817 2.7182817], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_compatible_pow = tf.math.pow(x_from_numpy_float32, 3)\n",
    "print(x_compatible_pow)\n",
    "\n",
    "x_compatible_log = tf.math.log(x_from_numpy_float32)\n",
    "print(x_compatible_log)\n",
    "\n",
    "x_compatible_exp = tf.math.exp(x_from_numpy_float32)\n",
    "print(x_compatible_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operazioni di riduzione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqXJio1HbAc0"
   },
   "source": [
    "A volte vogliamo fare operazioni su dimensioni specifiche di tensori, per es. medie e somme, per farlo abbiamo le operazioni reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1695395590368,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "6SABCyJMbAc1",
    "outputId": "8cf319f4-44fe-4307-cd8c-13380c72fc53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Somma le righe e mantieni la dimensione \n",
      " tf.Tensor(\n",
      "[[-31.45879    33.876328  -74.253586   -5.8108754 -52.091072   18.724203\n",
      "   21.157425   12.743502   35.47486    -3.8607616]], shape=(1, 10), dtype=float32)\n",
      "Somma le righe \n",
      " tf.Tensor(\n",
      "[-31.45879    33.876328  -74.253586   -5.8108754 -52.091072   18.724203\n",
      "  21.157425   12.743502   35.47486    -3.8607616], shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "numpy_array_normal = np.random.normal(0, 1, (1000, 10))\n",
    "x_normal = tf.convert_to_tensor(numpy_array_normal, dtype = tf.float32)\n",
    "\n",
    "print(\"Somma le righe e mantieni la dimensione \"+\"\\n\", tf.reduce_sum(x_normal, axis = 0, keepdims = True))\n",
    "print(\"Somma le righe \"+\"\\n\", tf.reduce_sum(x_normal, axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E per la media, massimo, minimo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.03145879  0.03387633 -0.07425359 -0.00581088 -0.05209107  0.0187242\n",
      "  0.02115742  0.0127435   0.03547486 -0.00386076], shape=(10,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[2.9985833 3.8766878 3.197682  2.7637267 3.1152568 2.8683956 3.2237716\n",
      " 2.9459667 3.508057  3.159443 ], shape=(10,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[-3.1706328 -3.2983055 -3.1361868 -3.1359913 -3.428623  -3.6864853\n",
      " -3.935677  -3.2548006 -2.7182446 -3.4848936], shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_mean(x_normal, axis = 0))\n",
    "print(tf.reduce_max(x_normal, axis = 0))\n",
    "print(tf.reduce_min(x_normal, axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uasie5HNbAc1"
   },
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tayxc8FibAc1"
   },
   "source": [
    "Come per numpy possiamo combinare tensori con le stesse dimensioni ma numero di elementi diversi tramite il broadcasting. Qui il tensore più piccolo viene proiettato su quello più grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 528,
     "status": "ok",
     "timestamp": 1695395572757,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "AK4NBDEpbAc1",
    "outputId": "d16a7635-2e45-45ab-e808-d72a8f4244af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di elementi per dimenisone per il primo tensore \n",
      " tf.Tensor([1000   10], shape=(2,), dtype=int32)\n",
      "Numero di elementi per dimenisone per il secondo tensore \n",
      " tf.Tensor([1000    1], shape=(2,), dtype=int32)\n",
      "Somma del primo tensore con il secondo tensore tramite broadcasting \n",
      " tf.Tensor(\n",
      "[[-0.6329824  -0.2533936  -0.5351025  ... -0.82629734 -0.8499723\n",
      "  -1.6239971 ]\n",
      " [ 1.0565451   0.42078948  1.3052891  ... -0.10117    -0.28716344\n",
      "  -0.08061808]\n",
      " [ 0.723187    1.2173228  -0.73405254 ...  2.1694133   0.6604266\n",
      "   1.2830296 ]\n",
      " ...\n",
      " [ 0.15205757 -0.04761548  0.31708777 ... -0.07093471  0.85323805\n",
      "   0.07431581]\n",
      " [-2.4619832   1.155306   -1.4286293  ...  0.86876893 -0.12824313\n",
      "   1.484722  ]\n",
      " [ 2.9173884   3.2346406   3.0532193  ...  1.4491718   1.9036044\n",
      "  -0.7789408 ]], shape=(1000, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "numpy_array_normal_1 = np.random.normal(0, 1, (1000, 10))\n",
    "x_normal_1 = tf.convert_to_tensor(numpy_array_normal_1, dtype = tf.float32)\n",
    "\n",
    "numpy_array_normal_2 = np.random.normal(0, 1, (1000, 1))\n",
    "x_normal_2 = tf.convert_to_tensor(numpy_array_normal_2, dtype = tf.float32)\n",
    "\n",
    "print(\"Numero di elementi per dimenisone per il primo tensore \"+\"\\n\",   tf.shape(x_normal_1))\n",
    "print(\"Numero di elementi per dimenisone per il secondo tensore \"+\"\\n\", tf.shape(x_normal_2))\n",
    "print(\"Somma del primo tensore con il secondo tensore tramite broadcasting \"+\"\\n\", x_normal_1 + x_normal_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvUU0LsmbAc2"
   },
   "source": [
    "Il tensore piccolo deve poter essere replicato un numero esatto di volte senza ambiguità, altrimenti abbiamo un errore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "error",
     "timestamp": 1695395668399,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "DvISlIjZbAc2",
    "outputId": "3763c1b6-ea3b-4852-d058-ac087d38cd84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di elementi per dimenisone per il primo tensore \n",
      " tf.Tensor([1000    2], shape=(2,), dtype=int32)\n",
      "Numero di elementi per dimenisone per il secondo tensore \n",
      " tf.Tensor([1000   10], shape=(2,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-29 08:59:58.531502: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: required broadcastable shapes\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} required broadcastable shapes [Op:AddV2] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumero di elementi per dimenisone per il primo tensore \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, tf\u001b[38;5;241m.\u001b[39mshape(x_normal_3))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumero di elementi per dimenisone per il secondo tensore \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,tf\u001b[38;5;241m.\u001b[39mshape(x_normal_1) )\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSomma del primo tensore con il secondo tensore tramite broadcasting \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[43mx_normal_1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_normal_3\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfwsl/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tfwsl/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:5888\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5887\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5888\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} required broadcastable shapes [Op:AddV2] name: "
     ]
    }
   ],
   "source": [
    "numpy_array_normal_3 = np.random.normal(0, 1, (1000, 2))\n",
    "x_normal_3 = tf.convert_to_tensor(numpy_array_normal_3, dtype = tf.float32)\n",
    "\n",
    "print(\"Numero di elementi per dimenisone per il primo tensore \"+\"\\n\", tf.shape(x_normal_3))\n",
    "print(\"Numero di elementi per dimenisone per il secondo tensore \"+\"\\n\",tf.shape(x_normal_1) )\n",
    "print(\"Somma del primo tensore con il secondo tensore tramite broadcasting \"+\"\\n\", x_normal_1 + x_normal_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtIh2R09bAc2"
   },
   "source": [
    "Possiamo correggere le dimensioni usando expand_dims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2099,
     "status": "ok",
     "timestamp": 1695395685090,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "JvVFzrqdbAc2",
    "outputId": "bf2526d8-1f37-4316-cd85-0b860bccc200"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di elementi per dimenisone per il primo tensore \n",
      " tf.Tensor([1000   10], shape=(2,), dtype=int32)\n",
      "Numero di elementi per dimenisone per il secondo tensore \n",
      " tf.Tensor([1000  100   10   50], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "numpy_array_normal_4 = np.random.normal(0, 1, (1000, 100, 10, 50))\n",
    "x_normal_4 = tf.convert_to_tensor(numpy_array_normal_4, dtype = tf.float32)\n",
    "\n",
    "print(\"Numero di elementi per dimenisone per il primo tensore \"+\"\\n\", tf.shape(x_normal_1))\n",
    "print(\"Numero di elementi per dimenisone per il secondo tensore \"+\"\\n\", tf.shape(x_normal_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSOzwnJbbAc2"
   },
   "source": [
    "Qui per esempio vogliamo espandere la seconda e l'ultima dimensione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1695395781405,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "WluzMfCCbAc2",
    "outputId": "5612f121-b39b-461f-cc8e-ae059ccb9c9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Somma del primo tensore con il secondo tensore tramite broadcasting \n",
      " tf.Tensor(540114.94, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_normal_expanded = tf.expand_dims(tf.expand_dims(x_normal_1, 1), -1)\n",
    "\n",
    "print(\"Somma del primo tensore con il secondo tensore tramite broadcasting \"+\"\\n\", tf.reduce_sum(x_normal_expanded + x_normal_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jj9VNJ5-bAc3"
   },
   "source": [
    "Nota che abbiamo portato come esempio la somma, ma il broadcasting funziona anche per differenza, prodotto, e divisione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P61wquF9bAc3"
   },
   "source": [
    "### Operazioni tra dimensioni con einsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9kVU1sZbAc3"
   },
   "source": [
    "La notazione di Einstein ci permette di effettuare operazioni di somma, prodotto, differenza, e divisione tra le dimensioni di tensori multidimensionali. Il caso più banale è il prodotto tra matrici e vettori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 1249,
     "status": "ok",
     "timestamp": 1695395877149,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "rQsRcu6dbAc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prodotto tra la matrice e il vettore \n",
      " tf.Tensor(\n",
      "[-3.5257294  -2.468877    0.99643743 -1.4330745  -5.08745    -5.1836786\n",
      " -1.5357137  -4.377594    1.1905733  -1.7942619 ], shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "numpy_array_A = np.random.normal(0, 1, (10, 10))\n",
    "A = tf.convert_to_tensor(numpy_array_A, dtype = tf.float32)\n",
    "\n",
    "numpy_array_b = np.random.normal(0, 1, (10))\n",
    "b = tf.convert_to_tensor(numpy_array_b, dtype = tf.float32)\n",
    "\n",
    "print(\"Prodotto tra la matrice e il vettore \"+\"\\n\", tf.einsum(\"ij,j->i\", A, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il grosso vantaggio è che possiamo farlo anche su tensori di matrici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prodotto tra tensori di matrici e di vettori \n",
      " tf.Tensor(\n",
      "[[[-2.9194183   1.4348356   1.4062337  ...  5.4584255   7.9114947\n",
      "    0.41593933]\n",
      "  [ 0.0102362   0.3842299  -1.7232189  ... -0.18307662 -1.5202118\n",
      "    2.564653  ]\n",
      "  [ 2.0685983   2.5460925   1.4458483  ...  3.3978298  -2.5723565\n",
      "   -2.134503  ]\n",
      "  ...\n",
      "  [ 1.8602633   2.1680176   1.675511   ...  1.0009179  -0.7119558\n",
      "    4.3088503 ]\n",
      "  [-0.2802956  -6.134557    8.279608   ...  3.3314757  -2.4269292\n",
      "   -3.6034746 ]\n",
      "  [-1.0705116   0.8496529   3.4393904  ...  0.01789801  4.4477725\n",
      "   -4.0888243 ]]\n",
      "\n",
      " [[ 2.6605475   1.6431581   4.0256686  ...  4.076202   -6.300973\n",
      "   -3.7376995 ]\n",
      "  [ 1.9049526   2.6993823  -1.9047573  ...  5.86748     2.5697565\n",
      "    3.413865  ]\n",
      "  [ 0.74447584 -1.9372935   1.0115457  ... -3.9164283   4.1718135\n",
      "   -0.3182931 ]\n",
      "  ...\n",
      "  [ 1.7953453  -1.5467398   1.4451729  ... -3.9533784   1.3394225\n",
      "    4.273911  ]\n",
      "  [-0.85293967 -3.186804    2.1247249  ...  0.20896015  7.469268\n",
      "   -0.60964215]\n",
      "  [-3.122695    0.15174896  4.608964   ...  2.7120953  -0.9440032\n",
      "    1.3246865 ]]\n",
      "\n",
      " [[-1.8092077   8.993658    4.159908   ...  3.4630451   3.73222\n",
      "   -3.0873227 ]\n",
      "  [ 0.11121699 -6.178187   -4.2975435  ...  5.418412    2.9872212\n",
      "   -7.16782   ]\n",
      "  [ 2.0511484  -4.179136   -0.5193267  ...  5.6932235   0.8700707\n",
      "   -1.6676649 ]\n",
      "  ...\n",
      "  [-1.6435113   7.915065   -3.497339   ...  2.6016657   2.2027545\n",
      "   -1.6319456 ]\n",
      "  [ 1.1497742   0.10701445 -1.4975383  ... -7.419473    7.3366413\n",
      "   -2.8793533 ]\n",
      "  [-0.23815262  3.044666    7.3684187  ...  2.644907   -0.3074942\n",
      "   -0.5194616 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.2892742   1.2924775  -0.84865135 ...  3.372978    0.5245178\n",
      "    2.5267837 ]\n",
      "  [ 0.98821867  3.2110481   0.8308105  ... -5.524762    0.2279054\n",
      "    3.4550192 ]\n",
      "  [-1.3801739  -6.5868025   1.697911   ... -3.5017753   2.3551624\n",
      "   -4.1856813 ]\n",
      "  ...\n",
      "  [-6.63448     5.7198095  -3.3121095  ...  3.26089     2.1273034\n",
      "    1.6314161 ]\n",
      "  [ 4.7499866  -4.1786275   2.352236   ... -1.2694141  -0.9322971\n",
      "   -0.5323808 ]\n",
      "  [-1.4096965  -9.05289    -2.010535   ...  1.0336301   2.4492278\n",
      "    3.1820674 ]]\n",
      "\n",
      " [[-0.07337201 -4.505489   -4.813483   ... -0.14569497  4.9226174\n",
      "   -1.0895317 ]\n",
      "  [-2.2938955  -2.3721883  -2.1540322  ... -3.9072604  -4.603453\n",
      "   -1.4340231 ]\n",
      "  [ 2.5861003   1.5266498  -1.1601181  ... -2.023117    2.1638684\n",
      "   -0.20099127]\n",
      "  ...\n",
      "  [ 1.369425   -0.8596798  -3.7287035  ...  2.1586485  -3.7580187\n",
      "    6.3715014 ]\n",
      "  [-2.5911927   0.78886056  6.0700245  ...  0.9629559  -0.3821848\n",
      "    1.0545453 ]\n",
      "  [ 0.37729573 -1.3333046  -5.5265937  ...  3.4689786  -3.3258357\n",
      "   -1.2338924 ]]\n",
      "\n",
      " [[ 5.0131145   9.412733   -2.3253927  ... -3.116573   -2.0700383\n",
      "    0.21873426]\n",
      "  [-0.6564983   4.941814   -4.4651937  ...  2.6251826   2.1725712\n",
      "   -1.2200336 ]\n",
      "  [-2.726202    1.3171705   1.3313048  ... -1.343182    0.94941765\n",
      "    0.7049627 ]\n",
      "  ...\n",
      "  [ 1.9215571  -4.201781    2.4142764  ...  3.109541   -0.33228683\n",
      "    1.2952132 ]\n",
      "  [ 6.211953    0.16381454 -3.0616596  ...  2.8029332  -4.2487206\n",
      "   -2.2742846 ]\n",
      "  [ 1.712708   -5.5977793  -3.9684062  ...  4.020054   -4.794106\n",
      "    4.6407347 ]]], shape=(1000, 100, 10), dtype=float32)\n",
      "Prodotto tra tensori di matrici e di vettori \n",
      " tf.Tensor(\n",
      "[[[-2.9194183   1.4348356   1.4062337  ...  5.4584255   7.9114947\n",
      "    0.41593933]\n",
      "  [ 0.0102362   0.3842299  -1.7232189  ... -0.18307662 -1.5202118\n",
      "    2.564653  ]\n",
      "  [ 2.0685983   2.5460925   1.4458483  ...  3.3978298  -2.5723565\n",
      "   -2.134503  ]\n",
      "  ...\n",
      "  [ 1.8602633   2.1680176   1.675511   ...  1.0009179  -0.7119558\n",
      "    4.3088503 ]\n",
      "  [-0.2802956  -6.134557    8.279608   ...  3.3314757  -2.4269292\n",
      "   -3.6034746 ]\n",
      "  [-1.0705116   0.8496529   3.4393904  ...  0.01789801  4.4477725\n",
      "   -4.0888243 ]]\n",
      "\n",
      " [[ 2.6605475   1.6431581   4.0256686  ...  4.076202   -6.300973\n",
      "   -3.7376995 ]\n",
      "  [ 1.9049526   2.6993823  -1.9047573  ...  5.86748     2.5697565\n",
      "    3.413865  ]\n",
      "  [ 0.74447584 -1.9372935   1.0115457  ... -3.9164283   4.1718135\n",
      "   -0.3182931 ]\n",
      "  ...\n",
      "  [ 1.7953453  -1.5467398   1.4451729  ... -3.9533784   1.3394225\n",
      "    4.273911  ]\n",
      "  [-0.85293967 -3.186804    2.1247249  ...  0.20896015  7.469268\n",
      "   -0.60964215]\n",
      "  [-3.122695    0.15174896  4.608964   ...  2.7120953  -0.9440032\n",
      "    1.3246865 ]]\n",
      "\n",
      " [[-1.8092077   8.993658    4.159908   ...  3.4630451   3.73222\n",
      "   -3.0873227 ]\n",
      "  [ 0.11121699 -6.178187   -4.2975435  ...  5.418412    2.9872212\n",
      "   -7.16782   ]\n",
      "  [ 2.0511484  -4.179136   -0.5193267  ...  5.6932235   0.8700707\n",
      "   -1.6676649 ]\n",
      "  ...\n",
      "  [-1.6435113   7.915065   -3.497339   ...  2.6016657   2.2027545\n",
      "   -1.6319456 ]\n",
      "  [ 1.1497742   0.10701445 -1.4975383  ... -7.419473    7.3366413\n",
      "   -2.8793533 ]\n",
      "  [-0.23815262  3.044666    7.3684187  ...  2.644907   -0.3074942\n",
      "   -0.5194616 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.2892742   1.2924775  -0.84865135 ...  3.372978    0.5245178\n",
      "    2.5267837 ]\n",
      "  [ 0.98821867  3.2110481   0.8308105  ... -5.524762    0.2279054\n",
      "    3.4550192 ]\n",
      "  [-1.3801739  -6.5868025   1.697911   ... -3.5017753   2.3551624\n",
      "   -4.1856813 ]\n",
      "  ...\n",
      "  [-6.63448     5.7198095  -3.3121095  ...  3.26089     2.1273034\n",
      "    1.6314161 ]\n",
      "  [ 4.7499866  -4.1786275   2.352236   ... -1.2694141  -0.9322971\n",
      "   -0.5323808 ]\n",
      "  [-1.4096965  -9.05289    -2.010535   ...  1.0336301   2.4492278\n",
      "    3.1820674 ]]\n",
      "\n",
      " [[-0.07337201 -4.505489   -4.813483   ... -0.14569497  4.9226174\n",
      "   -1.0895317 ]\n",
      "  [-2.2938955  -2.3721883  -2.1540322  ... -3.9072604  -4.603453\n",
      "   -1.4340231 ]\n",
      "  [ 2.5861003   1.5266498  -1.1601181  ... -2.023117    2.1638684\n",
      "   -0.20099127]\n",
      "  ...\n",
      "  [ 1.369425   -0.8596798  -3.7287035  ...  2.1586485  -3.7580187\n",
      "    6.3715014 ]\n",
      "  [-2.5911927   0.78886056  6.0700245  ...  0.9629559  -0.3821848\n",
      "    1.0545453 ]\n",
      "  [ 0.37729573 -1.3333046  -5.5265937  ...  3.4689786  -3.3258357\n",
      "   -1.2338924 ]]\n",
      "\n",
      " [[ 5.0131145   9.412733   -2.3253927  ... -3.116573   -2.0700383\n",
      "    0.21873426]\n",
      "  [-0.6564983   4.941814   -4.4651937  ...  2.6251826   2.1725712\n",
      "   -1.2200336 ]\n",
      "  [-2.726202    1.3171705   1.3313048  ... -1.343182    0.94941765\n",
      "    0.7049627 ]\n",
      "  ...\n",
      "  [ 1.9215571  -4.201781    2.4142764  ...  3.109541   -0.33228683\n",
      "    1.2952132 ]\n",
      "  [ 6.211953    0.16381454 -3.0616596  ...  2.8029332  -4.2487206\n",
      "   -2.2742846 ]\n",
      "  [ 1.712708   -5.5977793  -3.9684062  ...  4.020054   -4.794106\n",
      "    4.6407347 ]]], shape=(1000, 100, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "numpy_array_A = np.random.normal(0, 1, (1000, 100, 10, 10))\n",
    "A = tf.convert_to_tensor(numpy_array_A, dtype = tf.float32)\n",
    "\n",
    "numpy_array_b = np.random.normal(0, 1, (1000, 100, 10))\n",
    "b = tf.convert_to_tensor(numpy_array_b, dtype = tf.float32)\n",
    "\n",
    "print(\"Prodotto tra tensori di matrici e di vettori \"+\"\\n\", tf.einsum(\"nhij,nhj->nhi\", A, b))\n",
    "print(\"Prodotto tra tensori di matrici e di vettori \"+\"\\n\", tf.einsum(\"...ij,...j->...i\", A, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'importante è che le dimensioni su cui effettuiamo l'operazione rispettino le dimensioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prodotto tra tensori di matrici e di vettori \n",
      " tf.Tensor(\n",
      "[[[ 2.9430718  -3.3505454   1.8829994  ... -1.980938   -3.649519\n",
      "    2.6537714 ]\n",
      "  [ 1.2129307   1.7160871   3.7076519  ...  6.6553373   0.38693857\n",
      "    0.19331613]\n",
      "  [-1.6666896   2.3893676  -4.0232897  ... -1.9163061  -2.8786266\n",
      "    3.70921   ]\n",
      "  ...\n",
      "  [ 0.52798295  1.935235    3.6631703  ... -5.9439173  -1.3582886\n",
      "   -4.234736  ]\n",
      "  [-1.9224184   2.381717   -1.7632741  ...  4.1731033   3.425043\n",
      "    1.2571268 ]\n",
      "  [-5.7820616   0.32982516 -0.44966853 ... -0.13595901 -1.6004652\n",
      "    6.1476455 ]]\n",
      "\n",
      " [[-2.2108772  -1.7958032   0.38095593 ... -2.0926492   2.5734658\n",
      "    0.49307203]\n",
      "  [-0.80312324 -1.0848883  -0.70723504 ... -4.7339706   1.015989\n",
      "   -2.4657393 ]\n",
      "  [ 0.9322814  -1.8818929  -1.634514   ...  0.06296545 -3.124466\n",
      "   -0.634296  ]\n",
      "  ...\n",
      "  [ 3.5753555  -3.8374286  -3.3457603  ...  0.42999333 -4.0373697\n",
      "   -0.5925848 ]\n",
      "  [-0.7665982  -1.3450924   4.103297   ... -3.0481825   0.6273246\n",
      "    1.7084079 ]\n",
      "  [-3.0384617  -1.550501   -0.04281616 ...  0.18679577  2.2546935\n",
      "   -3.3658743 ]]\n",
      "\n",
      " [[ 1.8318608   2.0221295   0.7936428  ... -2.2339206   3.7353868\n",
      "   -3.7673671 ]\n",
      "  [-7.370063    0.3955642   1.1019375  ... -4.377343   -1.283076\n",
      "   -5.098667  ]\n",
      "  [ 5.4679956   3.683259   -2.4883559  ... -7.070364    3.8366227\n",
      "    0.23318931]\n",
      "  ...\n",
      "  [-1.3918628   4.059339   -0.49504    ...  3.2505999   3.1005712\n",
      "    1.5044714 ]\n",
      "  [ 8.078778    6.584943    4.809552   ...  4.804201    4.914992\n",
      "   -1.0522796 ]\n",
      "  [ 0.8910294   4.182606   -1.6872213  ...  4.0494857   2.0429592\n",
      "    2.3394346 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.3566473  -2.1299605   2.9384055  ...  3.1853032   4.3850307\n",
      "    4.2089934 ]\n",
      "  [-0.99808514 -6.805658    8.310757   ... -1.8154814   0.41802502\n",
      "    0.6452684 ]\n",
      "  [-4.022764   -0.05719638  1.3431103  ... -2.47359     0.98575664\n",
      "   -6.067636  ]\n",
      "  ...\n",
      "  [-2.9695735  -0.49782297 -2.742997   ...  3.4739826  -3.7351952\n",
      "    1.5561181 ]\n",
      "  [-1.3449035  -3.7572558   0.17092568 ...  3.4214098  -4.9131856\n",
      "   -2.6009283 ]\n",
      "  [-0.1998077  -4.846588    4.9089518  ...  3.1390514  -2.9380653\n",
      "    3.2870097 ]]\n",
      "\n",
      " [[-3.456647    1.1754386   1.1048852  ... -3.9317808   0.9532298\n",
      "   -1.7454326 ]\n",
      "  [ 0.075351   -3.772448    0.51627046 ...  0.40015256  5.572391\n",
      "   -3.3043737 ]\n",
      "  [ 6.566205    0.12514651  2.8576822  ... -1.7093514   1.802659\n",
      "    0.8060491 ]\n",
      "  ...\n",
      "  [ 1.38782     2.9236178   0.09922774 ... -1.0637357  -3.9282408\n",
      "   -4.1976867 ]\n",
      "  [-3.1081476  -0.6463845   0.13393408 ... -6.0866747   1.5361996\n",
      "   -4.8910213 ]\n",
      "  [ 0.949498    1.4156806  -2.9790301  ...  4.8016295   0.0956724\n",
      "   -1.8460877 ]]\n",
      "\n",
      " [[ 1.722688    1.1765953   2.1861887  ...  1.9231727  -1.4407113\n",
      "    3.6729054 ]\n",
      "  [ 0.4160536   4.259547    0.65362144 ... -1.7711368   0.94782823\n",
      "    0.02085859]\n",
      "  [-4.080571   -5.896838    2.9836226  ...  0.14733696  0.86179566\n",
      "   -1.585002  ]\n",
      "  ...\n",
      "  [ 1.2313796  -2.4935534  -2.1050403  ... -3.484686   -0.45810947\n",
      "   -8.81556   ]\n",
      "  [-1.9300766  -1.4848156   8.388911   ... -2.5120702  -5.0259485\n",
      "   -0.31131613]\n",
      "  [ 2.0100935   1.0667297  -1.6999377  ...  1.4923155  -1.6300453\n",
      "    2.086285  ]]], shape=(1000, 100, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "numpy_array_A = np.random.normal(0, 1, (1000, 100, 10, 10))\n",
    "A = tf.convert_to_tensor(numpy_array_A, dtype = tf.float32)\n",
    "\n",
    "numpy_array_b = np.random.normal(0, 1, (100, 10))\n",
    "b = tf.convert_to_tensor(numpy_array_b, dtype = tf.float32)\n",
    "\n",
    "print(\"Prodotto tra tensori di matrici e di vettori \"+\"\\n\", tf.einsum(\"...hij,hj->...hi\", A, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confronti di performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_array_A = np.random.normal(0, 1, (10000, 100, 10, 10))\n",
    "A = tf.convert_to_tensor(numpy_array_A, dtype = tf.float32)\n",
    "\n",
    "numpy_array_b = np.random.normal(0, 1, (10000, 100, 10))\n",
    "b = tf.convert_to_tensor(numpy_array_b, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gira in  0.802950382232666\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for n in range(10000):\n",
    "\tfor h in range(100):\n",
    "\n",
    "\t\tnp.matmul(numpy_array_A[n,h,...], numpy_array_b[n,h,...])\n",
    "\t\t\n",
    "print(\"Gira in \", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gira in  0.06720614433288574\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "np.einsum(\"nhij,nhj->nhi\", numpy_array_A, numpy_array_b)\t\t\n",
    "print(\"Gira in \", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gira in  0.0011544227600097656\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tf.einsum(\"nhij,nhj->nhi\", A, b)\t\t\n",
    "print(\"Gira in \", time.time()-start)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "https://github.com/LorenzoRimella/epidemiology_workshop/blob/main/Epidemics_and_ParallelComputing.ipynb",
     "timestamp": 1695397117267
    }
   ]
  },
  "kernelspec": {
   "display_name": "tfwsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
